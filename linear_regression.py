import numpy as np

def parameters_inititalization(m):
  """
  Ця функція ініціалізує вектор-рядок випадкових дійсних значень ваг форми (1, m),
  отриманих з нормального розподілу та зсув (довільне дійсне значення)

  Параметри:
  m -- кількість вхідних ознак для кожного навчального прикладу

  Повертає:
  W -- вектор-рядок ваг форми (1, m)
  b -- зсув (скаляр)
  """

  W = np.random.normal(0.0, 1, (1, m))
  b = np.random.normal(0.0, 1, )

  return W, b


def forwardPropagate(X, W, b):
  """
  Ця функція обчислює лінійну комбінацію вхідних ознак та ваг, включаючи зсув

  Параметри:
  X -- вхідний вектор ознак форми (m, X_train.shape[1])
  W -- вектор-рядок ваг форми (1, m)
  b -- зсув моделі (скаляр)

  Повертає:
  z -- загальна зважена сума вхідних ознак, включаючи зсув
  y_hat -- прогноз моделі
  """

  z = np.dot(W, X) + b
  y_hat = z

  return z, y_hat


def cost(n, y_hat, y_true):
  """
  Ця функція обчислює середнє квадратичне відхилення на всьому навчальному наборі даних

  Параметри:
  n -- загальна кількість навчальних прикладів
  y_hat -- вихідне значення лінійної регресії
  y_true -- істинне значення залежної змінної

  Повертає:
  J --  середнє квадратичне відхилення на всьому навчальному наборі даних
  """

  J = np.sum((y_hat - y_true) ** 2) / n

  return J


def backwardPropagate(n, X, y_hat, y_true):
  """
  Ця функція обчислює градієнти цільвої функції відносно ваг та зсуву

  Параметри:
  n -- загальна кількість навчальних прикладів
  X -- вхідний вектор ознак форми (1, X_train.shape[1])
  y_hat --  вихідне значення лінійної регресії
  y_true -- істинне значення залежної змінної

  Повертає:
  dW --  градієнт цільової функції відносно ваг моделі
  db -- градієнт цільової функції відносно зсуву моделі
  """

  diff = y_hat - y_true
  dW = 2 * np.sum(np.dot(diff, X.T)) / n
  db = 2 * np.sum(diff) / n

  return dW, db


def update(alpha, dW, db, W, b):
  """
  Ця функція оновлює навчальні параметри моделі (ваги та зсув ) у напрямку мінімізації цільової функції

  Параметри:
  alpha -- швидкість  навчання (крок навчання)
  dW --  градієнт цільової функції відносно ваг моделі
  db -- градієнт цільової функції відносно зсуву моделі
  W -- вектор-рядок ваг моделі форми (1, m)
  b -- зсув моделі (скаляр)

  Повертає:
  W -- оновлений вектор-рядок ваг моделі форми (1, m)
  b -- оновлений зсув моделі (скаляр)
  """

  W = W - alpha * dW
  b = b - alpha * db

  return W, b
